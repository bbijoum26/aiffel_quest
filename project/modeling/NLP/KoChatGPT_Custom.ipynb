{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75027be8",
   "metadata": {},
   "source": [
    "# 프로젝트: KoChatGPT 업그레이드 하기\n",
    "### **`Unable to render code block` 때문에 출력값이 없습니다. 해결하면 수정하겠습니다.**  \n",
    "\n",
    "\n",
    "KoChatGPT 소스코드를 바탕으로 다양한 모델 개선 전략을 선택해 KoChatGPT를 업그레이드해 본다.  \n",
    "제시된 전략 중 하나를 선택하거나 여러 개를 조합하여 custom ChatGPT를 개발\n",
    "\n",
    "평가문항\n",
    "1. 기존 KoGPT2와 SFT 적용 모델 결과 분석했는가?\n",
    "    - 기존 모델의 결과물과 SFT를 적용한 모델의 결과물을 정량/정성적으로 비교/분석했다.\n",
    "2. SFT 모델과 RM 모델 결과 분석을 해보았는가?\t\n",
    "    - SFT를 적용한 모델의 결과물과 RM을 적용한 모델의 결과물을 정량/정성적으로 비교/분석했다.\n",
    "3. 데이터셋 정제 / 새로운 데이터셋 / foundation model 교체 중 하나를 이용해 정량적 성능 향상을 해보았는가?\t\n",
    "    - 기존 데이터셋을 추가로 정제하고, generation 성능을 올리기 위한 기법(Beam search, Top-k sampling 등)을 실험해 모델 성능을 향상시켰다.\n",
    "    - 새로운 데이터를 수집해 전처리를 수행하여 모델의 성능을 향상시켰다.\n",
    "    - 더 적절한 학습 전략(SFT, RM, PPO)을 적용하거나 initial model을 변경해 모델의 성능을 향상시켰다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd2c126",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "```python\n",
    "!pip uninstall torch -y\n",
    "!pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "\n",
    "# for transformers, 최신버전은 에러발생\n",
    "!pip install transformers==4.35.2\n",
    "!pip install accelerate==0.24.1\n",
    "\n",
    "# for ColossalAI\n",
    "!pip install colossalai==0.2.7\n",
    "\n",
    "# setup data\n",
    "!git clone https://github.com/airobotlab/KoChatGPT\n",
    "!mv KoChatGPT/data_kochatgpt .\n",
    "!mv KoChatGPT/img .\n",
    "\n",
    "%cd KoChatGPT/colossalai_ChatGPT_230319/\n",
    "!pip install .\n",
    "%cd ../../\n",
    "\n",
    "# setup library\n",
    "!pip install openai\n",
    "!pip install langchain==0.0.113\n",
    "!pip install pandas>=1.4.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6513ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "print(\"Torch version:{}\".format(torch.__version__))\n",
    "print(\"Cuda version: {}\".format(torch.version.cuda))\n",
    "print(\"transformers version: {}\".format(transformers.__version__))\n",
    "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))\n",
    "print(\"GPU 사용 가능여부: {}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac04dd",
   "metadata": {},
   "source": [
    "## 기존 데이터셋 추가 정제\n",
    "\n",
    "data_kochatgpt 폴더  \n",
    "- kochatgpt_1_SFT.jsonl : SFT를 위한 prompt와 completion 문장셋\n",
    "    - prompt: 모델이 응답을 생성하기 위해 받는 입력 문장\n",
    "    - completion: 해당 \"prompt\"에 대한 올바른 응답 또는 완성 문장\n",
    "- kochatgpt_1_RM.jsonl : RM 학습을 위한 prompt와 세 가지 ranking 문장셋  \n",
    "- kochatgpt_1_PPO.jsonl : promt 문장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49caed",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0a22a",
   "metadata": {},
   "source": [
    "#### JSONL 파일 로딩 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_data = load_jsonl('./data_kochatgpt/kochatgpt_1_SFT.jsonl')\n",
    "rm_data = load_jsonl('./data_kochatgpt/kochatgpt_2_RM.jsonl')\n",
    "ppo_data = load_jsonl('./data_kochatgpt/kochatgpt_3_PPO.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42447bdd",
   "metadata": {},
   "source": [
    "### 데이터셋 EDA 및 전처리\n",
    "주어진 데이터셋(kochatgpt_1_SFT.jsonl, kochatgpt_1_RM.jsonl, kochatgpt_1_PPO.jsonl)에 대한   \n",
    "탐색적 데이터 분석(EDA)을 수행하고, 이를 바탕으로 데이터 전처리 및 정제 작업 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9edb68",
   "metadata": {},
   "source": [
    "#### 데이터셋 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ca6b8",
   "metadata": {},
   "source": [
    "**sft_data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9c006",
   "metadata": {},
   "source": [
    "- 데이터 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae1beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84835610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sft_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592c9b3",
   "metadata": {},
   "source": [
    "- 가장 많이 등장하는 단어 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60060ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(\" \".join(sft_data['prompt']).split()).most_common(10)\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3f5d0",
   "metadata": {},
   "source": [
    "- 'prompt' 열에서 가장 많이 등장하는 단어 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_data['prompt_length'] = sft_data['prompt'].apply(len)\n",
    "sft_data['completion_length'] = sft_data['completion'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78487975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sft_data[['prompt_length', 'completion_length']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74953b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(sft_data['prompt_length'], bins=50, alpha=0.5, label='Prompt Length')\n",
    "plt.hist(sft_data['completion_length'], bins=50, alpha=0.5, label='Completion Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.title('Length Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5037af",
   "metadata": {},
   "source": [
    "- 'completion' 열에서 문장 끝이 온점('.')으로 끝나는 비율 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_with_period = sft_data['completion'].apply(lambda x: x.endswith('.')).mean()\n",
    "print(f\"Percentage of completions that end with a period: {end_with_period * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a27ec0",
   "metadata": {},
   "source": [
    "**rm_data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e4f64",
   "metadata": {},
   "source": [
    "- 데이터 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc5d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f2017",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rm_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a92097",
   "metadata": {},
   "source": [
    "- 가장 많이 등장하는 단어 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc50bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(\" \".join(rm_data['prompt']).split()).most_common(10)\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d342e0",
   "metadata": {},
   "source": [
    "- 'prompt' 열에서 가장 많이 등장하는 단어 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_data['prompt_length'] = rm_data['prompt'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e220f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rm_data['prompt_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(rm_data['prompt_length'], bins=50, alpha=0.5, label='Prompt Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.title('Length Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e94b424",
   "metadata": {},
   "source": [
    "**ppo_data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0863512",
   "metadata": {},
   "source": [
    "- 데이터 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db5f51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ppo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e52c18",
   "metadata": {},
   "source": [
    "- 가장 많이 등장하는 단어 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(\" \".join(ppo_data['prompt']).split()).most_common(10)\n",
    "print(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e28b50",
   "metadata": {},
   "source": [
    "- 'prompt' 열에서 가장 많이 등장하는 단어 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_data['prompt_length'] = ppo_data['prompt'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e2f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppo_data['prompt_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(ppo_data['prompt_length'], bins=50, alpha=0.5, label='Prompt Length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.title('Length Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb5df4f",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c444d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # HTML 태그 제거\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # 이메일 주소 제거\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n",
    "    # URL 제거\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    # 특수 문자 및 숫자 제거 (옵션)\n",
    "    text = re.sub(r'[^가-힣\\s]', '', text)\n",
    "    return text.strip()  # 양쪽 공백 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2e3e2",
   "metadata": {},
   "source": [
    "- 데이터에 텍스트 정제 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_data['prompt'] = sft_data['prompt'].apply(clean_text)\n",
    "sft_data['completion'] = sft_data['completion'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eddf191",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_data['prompt'] = rm_data['prompt'].apply(clean_text)\n",
    "rm_data['completion_0'] = rm_data['completion_0'].apply(clean_text)\n",
    "rm_data['completion_1'] = rm_data['completion_1'].apply(clean_text)\n",
    "rm_data['completion_2'] = rm_data['completion_2'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc1763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_data['prompt'] = ppo_data['prompt'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eaf0a5",
   "metadata": {},
   "source": [
    "#### 데이터 json로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a34e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_data.to_json('./data_kochatgpt/data_cleaning_sft.jsonl', orient='records', lines=True, force_ascii=False)\n",
    "rm_data.to_json('./data_kochatgpt/data_cleaning_rm.jsonl', orient='records', lines=True, force_ascii=False)\n",
    "ppo_data.to_json('./data_kochatgpt/data_cleaning_ppo.jsonl', orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b36847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdf0b6",
   "metadata": {},
   "source": [
    "## SFT(Supervised Fine Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87023ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sft = load_jsonl('./data_kochatgpt/data_cleaning_sft.jsonl')\n",
    "data_sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c93774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
    "from copy import deepcopy\n",
    "from torch.optim import Adam\n",
    "from transformers import AutoTokenizer, BloomTokenizerFast\n",
    "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass, field\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "from typing import Optional, Dict, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d2355",
   "metadata": {},
   "source": [
    "### define argment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_path_1_SFT', type=str, default='./data_kochatgpt/data_cleaning_sft.jsonl')\n",
    "parser.add_argument('--model_name', type=str, default='gpt2', choices=['gpt2', 'bloom', 'opt'])\n",
    "parser.add_argument('--max_epochs', type=int, default=2)\n",
    "parser.add_argument('--train_batch_size', type=int, default=8)\n",
    "parser.add_argument('--output_dir', type=str, default='./output_cleaning_sft')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# for test\n",
    "args.model_name = 'skt/kogpt2-base-v2'  # SK GPT2, https://github.com/SKT-AI/KoGPT2\n",
    "# args.model_name = 'ajoublue-gpt2-base'  # 아주대, https://github.com/HeegyuKim/language-model\n",
    "\n",
    "args.max_epochs = 2\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df890e43",
   "metadata": {},
   "source": [
    "### test & load skt gpt2 kroean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
    "                                                    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
    "                                                    pad_token='<pad>', mask_token='<mask>')\n",
    "print(tokenizer.tokenize(\"안녕하세요. 한국어 GPT-2 입니다.😤:)l^o\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d547a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
    "text = '근육이 커지기 위해서는'\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "gen_ids = model.generate(input_ids,\n",
    "                         max_length=128,\n",
    "                         repetition_penalty=2.0,\n",
    "                         pad_token_id=tokenizer.pad_token_id,\n",
    "                         eos_token_id=tokenizer.eos_token_id,\n",
    "                         bos_token_id=tokenizer.bos_token_id,\n",
    "                         use_cache=True)\n",
    "generated = tokenizer.decode(gen_ids[0])\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "generation_args = dict(\n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "generator(\n",
    "    [\"0 : **는 게임 좋아하니\\n1 :\",\n",
    "    \"0 : 어제 강남에서 살인사건 났대 ㅜㅜ 너무 무서워\\n1 : 헐 왜? 무슨 일 있었어?\\n0 : 사진보니까 막 피흘리는 사람있고 경찰들이 떠서 제압하고 난리도 아니었다던데??\\n1 :\",\n",
    "    \"0 : 자기야 어제는 나한테 왜 그랬어?\\n1 : 뭔 일 있었어?\\n0 : 어떻게 나한테 말도 없이 그럴 수 있어? 나 진짜 실망했어\\n1 : \"],\n",
    "    **generation_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d4a4c",
   "metadata": {},
   "source": [
    "### data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f6ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"</s>\"\n",
    "DEFAULT_UNK_TOKEN = \"</s>\"\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context.\\n\"\n",
    "        \"아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다.\\n\\n\"\n",
    "        \"Write a response that appropriately completes the request.\\n요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Input(입력):\\n{input}\\n\\n### Response(응답):\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task.\\n\"\n",
    "        \"아래는 작업을 설명하는 명령어입니다.\\n\\n\"\n",
    "        \"Write a response that appropriately completes the request.\\n명령어에 따른 요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a06874f",
   "metadata": {},
   "source": [
    "### Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238dd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(args.model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    args.model_name,\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "tokenizer.add_special_tokens(\n",
    "    {\n",
    "        \"eos_token\": DEFAULT_EOS_TOKEN,\n",
    "        \"bos_token\": DEFAULT_BOS_TOKEN,\n",
    "        \"unk_token\": DEFAULT_UNK_TOKEN,\n",
    "    }\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085ba92",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb595d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SFT_dataset(Dataset):\n",
    "    '''SFT dataset by wygo'''\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        ## format\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_input = 'input'         # 내 데이터엔 input이 없다\n",
    "        pattern_output = 'completion'   # output\n",
    "\n",
    "        # data_path_1_SFT = './data_kochatgpt/data_cleaning_sft.jsonl'\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = load_jsonl(data_path_1_SFT) \n",
    "            if verbose:\n",
    "                print('## data check ##')\n",
    "                print((list_data_dict[0]))\n",
    " \n",
    "        ## 데이터셋 만들기, source와 target\n",
    "        prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]  # 템플릿 가져오기\n",
    "\n",
    "        # 입력\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            if example.get(pattern_input, \"\") != \"\":\n",
    "                tmp = prompt_input.format_map(example)\n",
    "            else:\n",
    "                tmp = prompt_no_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        # 출력\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "\n",
    "        if verbose:\n",
    "            idx = 0\n",
    "            print((sources[idx]))\n",
    "            print((targets[idx]))\n",
    "            print(\"Tokenizing inputs... This may take some time...\")\n",
    "\n",
    "        # data_dict = preprocess(sources, targets, tokenizer)  # https://github.com/Beomi/KoAlpaca/blob/04704348d58b8b1c2e2638d6437a04b4e8ba1823/train.py#L124\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        # source data tokenized\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source만\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "\n",
    "        ## 입력은 source, 출력은 source+target 이지만 학습은 target 부분만\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = IGNORE_INDEX  # source 부분은 -100으로 채운다\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        \"\"\"Tokenize a list of strings.\"\"\"\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object):\n",
    "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3deb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SFT_dataset(data_path_1_SFT=args.data_path_1_SFT, tokenizer=tokenizer)\n",
    "eval_dataset  = None  # eval은 안함\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "# check\n",
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455eca88",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ca671",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./test\",           # The output directory\n",
    "    overwrite_output_dir=True,     # overwrite the content of the output directory\n",
    "    num_train_epochs=3,            # number of training epochs\n",
    "    per_device_train_batch_size=4, # batch size for training\n",
    "    per_device_eval_batch_size=4,  # batch size for evaluation\n",
    "    eval_steps=3,                  # Number of update steps between two evaluations.\n",
    "    save_steps=500,                # after # steps model is saved\n",
    "    warmup_steps=5,                # number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec603a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2e9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_save_model_for_hf_trainer(trainer: transformers.Trainer, output_dir: str):\n",
    "    \"\"\"Collects the state dict and dump to disk.\"\"\"\n",
    "    state_dict = trainer.model.state_dict()\n",
    "    if trainer.args.should_save:\n",
    "        cpu_state_dict = {key: value.cpu() for key, value in list(state_dict.items())}\n",
    "        del state_dict\n",
    "        trainer._save(output_dir, state_dict=cpu_state_dict)  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb29d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_state()\n",
    "safe_save_model_for_hf_trainer(trainer=trainer, output_dir=args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198cfdaf",
   "metadata": {},
   "source": [
    "### Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model=args.output_dir, tokenizer=tokenizer)\n",
    "# generator = pipeline('text-generation', model=model.cpu(), tokenizer=tokenizer, config={'max_length':800})\n",
    "\n",
    "generation_args = dict(\n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n\n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어',\n",
    "               '오늘 미세먼지 어때?']\n",
    "list_prompt = [PROMPT_DICT['prompt_no_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)\n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print(('#'*70))\n",
    "    print(('completion: %s'%(result[0]['generated_text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601bc4a5",
   "metadata": {},
   "source": [
    "## RM(Reward Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ebfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for ColossalAI\n",
    "# !pip install colossalai==0.2.7\n",
    "\n",
    "# # setup data\n",
    "# !git clone https://github.com/airobotlab/KoChatGPT\n",
    "# !mv KoChatGPT/data_kochatgpt .\n",
    "# !mv KoChatGPT/img .\n",
    "\n",
    "# %cd KoChatGPT/colossalai_ChatGPT_230319/\n",
    "# !pip install .\n",
    "# %cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2769a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rm = load_jsonl('./data_kochatgpt/data_cleaning_rm.jsonl')\n",
    "data_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d48aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import loralib as lora\n",
    "torch.cuda.empty_cache()\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.bloom import BLOOMRM\n",
    "from chatgpt.models.gpt import GPTRM\n",
    "from chatgpt.models.opt import OPTRM\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import ColossalAIStrategy, DDPStrategy, NaiveStrategy\n",
    "from chatgpt.models.base import RewardModel\n",
    "from datasets import load_dataset\n",
    "from torch.optim import Adam\n",
    "from transformers import AutoTokenizer, BloomTokenizerFast\n",
    "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
    "from colossalai.nn.optimizer import HybridAdam\n",
    "from typing import Optional\n",
    "import torch.nn as nn\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abca48",
   "metadata": {},
   "source": [
    "### data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"</s>\"\n",
    "DEFAULT_UNK_TOKEN = \"</s>\"\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context.\\n\"\n",
    "        \"아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다.\\n\\n\"\n",
    "        \"Write a response that appropriately completes the request.\\n요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Input(입력):\\n{input}\\n\\n### Response(응답):\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task.\\n\"\n",
    "        \"아래는 작업을 설명하는 명령어입니다.\\n\\n\"\n",
    "        \"Write a response that appropriately completes the request.\\n명령어에 따른 요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790f95e",
   "metadata": {},
   "source": [
    "### define argment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb8057",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_dir', type=str, default='./output_cleaning_rm')\n",
    "parser.add_argument('--data_path_2_RM', type=str, default='./data_kochatgpt/data_cleaning_rm.jsonl', help='https://huggingface.co/datasets/fka/awesome-chatgpt-prompts/blob/main/prompts.csv')\n",
    "parser.add_argument('--strategy',\n",
    "                    choices=['naive', 'ddp', 'colossalai_gemini', 'colossalai_zero2'],\n",
    "                    default='naive')\n",
    "parser.add_argument('--model', type=str, default='gpt2', choices=['gpt2', 'bloom', 'opt'])\n",
    "parser.add_argument('--pretrain', type=str, default=None)\n",
    "parser.add_argument('--dataset', type=str, default='Dahoas/rm-static')\n",
    "parser.add_argument('--save_path', type=str, default='rm_ckpt.pth')\n",
    "parser.add_argument('--max_epochs', type=int, default=10)\n",
    "parser.add_argument('--batch_size', type=int, default=4)\n",
    "parser.add_argument('--lora_rank', type=int, default=0, help=\"low-rank adaptation matrices rank\")\n",
    "parser.add_argument('--max_len', type=int, default=512)  # wygo 추가\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# for test\n",
    "args.max_epochs = 3\n",
    "args.pretrain = 'skt/kogpt2-base-v2'  # pretrained 모델 가져오기\n",
    "args.verbose = True\n",
    "\n",
    "print(args)\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0d973e",
   "metadata": {},
   "source": [
    "### configure strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.strategy == 'naive':\n",
    "    strategy = NaiveStrategy()\n",
    "elif args.strategy == 'ddp':\n",
    "    strategy = DDPStrategy()\n",
    "elif args.strategy == 'colossalai_gemini':\n",
    "    strategy = ColossalAIStrategy(stage=3, placement_policy='cuda')\n",
    "elif args.strategy == 'colossalai_zero2':\n",
    "    strategy = ColossalAIStrategy(stage=2, placement_policy='cuda')\n",
    "else:\n",
    "    raise ValueError(f'Unsupported strategy \"{args.strategy}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "    \"\"\"\n",
    "    GPT Reward model.\n",
    "    Args:\n",
    "        pretrained (str): Pretrained model name or path.\n",
    "        config (GPT2Config): Model config.\n",
    "        checkpoint (bool): Enable gradient checkpointing.\n",
    "        lora_rank (int): Rank of the low-rank approximation.\n",
    "        lora_train_bias (str): LoRA bias training mode.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))  # wygo 추가!!!\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "\n",
    "        # model = model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        # 추가, 230421\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "    # 추가, 230421, config.json을 생성하기 위해 추가\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91cc84",
   "metadata": {},
   "source": [
    "### configure model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cb9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.model_init_context():\n",
    "    # load pretrained gpt2\n",
    "    if args.model == 'gpt2':\n",
    "        # tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        # tokenizer = AutoTokenizer.from_pretrained(args.pretrain)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.pretrain, padding_side=\"right\", model_max_length=512)\n",
    "        tokenizer.add_special_tokens(\n",
    "            {\n",
    "                \"eos_token\": DEFAULT_EOS_TOKEN,\n",
    "                \"bos_token\": DEFAULT_BOS_TOKEN,\n",
    "                \"unk_token\": DEFAULT_UNK_TOKEN,\n",
    "            }\n",
    "        )\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model = GPTRM_custom(pretrained=args.pretrain, lora_rank=args.lora_rank, tokenizer=tokenizer).cuda()\n",
    "\n",
    "    elif args.model == 'bloom':\n",
    "        model = BLOOMRM(pretrained=args.pretrain, lora_rank=args.lora_rank).cuda()\n",
    "        tokenizer = BloomTokenizerFast.from_pretrained(args.pretrain)\n",
    "\n",
    "    elif args.model == 'opt':\n",
    "        model = OPTRM(pretrained=args.pretrain, lora_rank=args.lora_rank).cuda()\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported model \"{args.model}\"')\n",
    "\n",
    "\n",
    "    # model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e13b8d",
   "metadata": {},
   "source": [
    "### make ranking data to chosen, rejetced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(args.data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "#     list_data_dict = json.load(json_file)\n",
    "#     if args.verbose:\n",
    "#         print('## data check ##')\n",
    "#         print((list_data_dict[0]))\n",
    "with open(args.data_path_2_RM, \"r\", encoding='utf-8-sig') as file:\n",
    "    list_data_dict = [json.loads(line) for line in file]\n",
    "    if args.verbose:\n",
    "        print('## data check ##')\n",
    "        print((list_data_dict[0]))\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    # data 1) 0 VS 1\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "    # data 2) 0 VS 2\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    # data 1) 1 VS 2\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4af203",
   "metadata": {},
   "source": [
    "### prepare for data and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5eb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "# list_tmp = list(range(10))\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])\n",
    "\n",
    "# train_data = total_data_ranking2chosen[:-1000]  # 29000 학습\n",
    "# eval_data = total_data_ranking2chosen[-1000:0]  # 1000개만 평가\n",
    "\n",
    "train_data = total_data_ranking2chosen[:100]  # 29000 학습\n",
    "eval_data = total_data_ranking2chosen[100:130]  # 1000개만 평가\n",
    "\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, args.max_len)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, args.max_len)\n",
    "\n",
    "# check\n",
    "idx = 10\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1954cf",
   "metadata": {},
   "source": [
    "### configure optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.strategy.startswith('colossalai'):\n",
    "    optim = HybridAdam(model.parameters(), lr=5e-5)\n",
    "else:\n",
    "    optim = Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1dba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size here is expected to be C(k,2), k means # response of each prompt\n",
    "# be limited with the format of dataset 'Dahoas/rm-static', we'd better use batch_size as 1\n",
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=strategy,\n",
    "                             optim=optim,\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=args.batch_size,\n",
    "                             max_epochs=args.max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf516d",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e451445",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(use_lora=args.lora_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eccd6a6",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a443091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model checkpoint after fitting on only rank0\n",
    "strategy.save_model(model, os.path.join(args.output_dir, 'RM.pt'), only_rank0=True)\n",
    "# save optimizer checkpoint on all ranks\n",
    "strategy.save_optimizer(optim,\n",
    "                        os.path.join(args.output_dir, 'RM_optim_checkpoint_%d.pt' % (torch.cuda.current_device())),\n",
    "                        only_rank0=False)\n",
    "\n",
    "model.save_pretrained(args.output_dir)  # config.json 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보상모델 체크\n",
    "def inference_RM(input_text='인공지능은 인공지능 입니다'):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "\n",
    "# input_text = '한국은 대한민국 입니다'\n",
    "input_text = '인공지능은 인공지능 입니다'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82fcdc",
   "metadata": {},
   "source": [
    "## PPO(Proximal Policy Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6459ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ppo = load_jsonl('./data_kochatgpt/data_cleaning_ppo.jsonl')\n",
    "data_ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d87b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from copy import deepcopy\n",
    "torch.cuda.empty_cache()\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.bloom import BLOOMActor, BLOOMCritic\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.models.opt import OPTActor, OPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import ColossalAIStrategy, DDPStrategy, NaiveStrategy\n",
    "from torch.optim import Adam\n",
    "from transformers import AutoTokenizer, BloomTokenizerFast\n",
    "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
    "from colossalai.nn.optimizer import HybridAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## wy 추가\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "## clossalAI error 해결\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['LOCAL_RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '2'\n",
    "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "os.environ['MASTER_PORT'] = '42043'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c769267d",
   "metadata": {},
   "source": [
    "### data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"</s>\"\n",
    "DEFAULT_UNK_TOKEN = \"</s>\"\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context.\\n\"\n",
    "        \"아래는 작업을 설명하는 명령어와 추가적 맥락을 제공하는 입력이 짝을 이루는 예제입니다.\\n\\n\"\n",
    "        \"Write a response that appropriately completes the request.\\n요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Input(입력):\\n{input}\\n\\n### Response(응답):\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task.\\n\"\n",
    "        \"아래는 작업을 설명하는 명령어입니다.\\n\\n\"\n",
    "        \"Write a response that appropriately completes the request.\\n명령어에 따른 요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737cbb2",
   "metadata": {},
   "source": [
    "### define argment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_path_3_PPO', type=str, default='./data_kochatgpt/data_cleaning_ppo.jsonl')\n",
    "parser.add_argument('--output_dir', type=str, default='./output_cleaning_ppo')\n",
    "parser.add_argument('--strategy',\n",
    "                    choices=['naive', 'ddp', 'colossalai_gemini', 'colossalai_zero2'],\n",
    "                    default='naive')\n",
    "parser.add_argument('--model', type=str, default='gpt2', choices=['gpt2', 'bloom', 'opt'])\n",
    "parser.add_argument('--pretrain', type=str, default=None)\n",
    "parser.add_argument('--num_episodes', type=int, default=10)\n",
    "parser.add_argument('--max_timesteps', type=int, default=3)\n",
    "parser.add_argument('--update_timesteps', type=int, default=3)\n",
    "parser.add_argument('--max_epochs', type=int, default=5)\n",
    "parser.add_argument('--train_batch_size', type=int, default=8)\n",
    "parser.add_argument('--lora_rank', type=int, default=0, help=\"low-rank adaptation matrices rank\")\n",
    "parser.add_argument('--max_length', type=int, default=250)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# for test\n",
    "args.output_dir = './output_cleaning_ppo'\n",
    "args.pretrain = 'skt/kogpt2-base-v2'  # pretrained 모델 가져오기\n",
    "\n",
    "\n",
    "## 이곳 수정!!\n",
    "args.pretrain_actor = './output_cleaning_sft'  # SFT 모델 가져오기\n",
    "args.pretrain_critic = './output_cleaning_rm'  # RM 모델 가져오기\n",
    "# args.pretrain_actor = args.pretrain\n",
    "# args.pretrain_critic = args.pretrain\n",
    "\n",
    "args.num_episodes = 1\n",
    "args.max_epochs   = 1\n",
    "\n",
    "print(args)\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4fb85b",
   "metadata": {},
   "source": [
    "### configure strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.strategy == 'naive':\n",
    "    strategy = NaiveStrategy()\n",
    "elif args.strategy == 'ddp':\n",
    "    strategy = DDPStrategy()\n",
    "elif args.strategy == 'colossalai_gemini':\n",
    "    strategy = ColossalAIStrategy(stage=3, placement_policy='cuda')\n",
    "elif args.strategy == 'colossalai_zero2':\n",
    "    strategy = ColossalAIStrategy(stage=2, placement_policy='cuda')\n",
    "else:\n",
    "    raise ValueError(f'Unsupported strategy \"{args.strategy}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17b0cd",
   "metadata": {},
   "source": [
    "### configure model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bfbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.model_init_context():\n",
    "    if args.model == 'gpt2':\n",
    "        actor = GPTActor(pretrained=args.pretrain_actor, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
    "        critic = GPTCritic(pretrained=args.pretrain_critic, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
    "        # tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        # tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenizer = AutoTokenizer.from_pretrained(args.pretrain, padding_side=\"right\", model_max_length=512)\n",
    "        tokenizer.add_special_tokens(\n",
    "            {\n",
    "                \"eos_token\": DEFAULT_EOS_TOKEN,\n",
    "                \"bos_token\": DEFAULT_BOS_TOKEN,\n",
    "                \"unk_token\": DEFAULT_UNK_TOKEN,\n",
    "            }\n",
    "        )\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "\n",
    "    elif args.model == 'bloom':\n",
    "        actor = BLOOMActor(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
    "        critic = BLOOMCritic(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
    "        tokenizer = BloomTokenizerFast.from_pretrained(args.pretrain)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    elif args.model == 'opt':\n",
    "        actor = OPTActor(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
    "        critic = OPTCritic(pretrained=args.pretrain, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported model \"{args.model}\"')\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3114b2f",
   "metadata": {},
   "source": [
    "### configure optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.strategy.startswith('colossalai'):\n",
    "    actor_optim = HybridAdam(actor.parameters(), lr=5e-6)\n",
    "    critic_optim = HybridAdam(critic.parameters(), lr=5e-6)\n",
    "else:\n",
    "    actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "    critic_optim = Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb7d9d1",
   "metadata": {},
   "source": [
    "### setting the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = strategy.prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e789e",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a0c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare data\n",
    "# with open(args.data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "#     list_data_dict = json.load(json_file)\n",
    "#     list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "with open(args.data_path_3_PPO, \"r\", encoding='utf-8-sig') as file:\n",
    "    list_data_dict = [json.loads(line.strip()) for line in file if line.strip()]\n",
    "    # prompt만 추출\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}\n",
    "\n",
    "print(list_prompt)\n",
    "print('\\n\\n\\n')\n",
    "print(tokenize_fn('I want you to act as a linux terminal.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e235aa7",
   "metadata": {},
   "source": [
    "### configure trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(strategy,\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=args.max_epochs,\n",
    "                     train_batch_size=args.train_batch_size,\n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a273238e",
   "metadata": {},
   "source": [
    "### train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc770d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(list_prompt,  # 입력 prompt\n",
    "            num_episodes=args.num_episodes,\n",
    "            max_timesteps=args.max_timesteps,\n",
    "            update_timesteps=args.update_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170d7161",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a26c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model checkpoint after fitting on only rank0\n",
    "strategy.save_model(actor, os.path.join(args.output_dir, 'actor.pt'), only_rank0=True)\n",
    "# save optimizer checkpoint on all ranks\n",
    "strategy.save_optimizer(actor_optim,\n",
    "                        os.path.join(args.output_dir, 'actor_optim_checkpoint_%d.pt' % (torch.cuda.current_device())),\n",
    "                        only_rank0=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b190e34",
   "metadata": {},
   "source": [
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc27a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=args.max_length,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print('#' * 70)\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?',\n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_no_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf7472f",
   "metadata": {},
   "source": [
    "## 결과 및 성능 비교\n",
    "- 응답의 자연스러움과 정확성\n",
    "    - 2번 코드는 데이터 전처리와 모델 학습 과정에서의 세심한 최적화를 통해 더 자연스러우면서도 정확한 응답을 생성합니다. \n",
    "    - 특히, SFT와 RM, PPO 접근법을 통합적으로 적용함으로써 모델이 인간의 언어를 더 잘 이해하고 반영할 수 있도록 도와줍니다.\n",
    "- 모델의 범용성\n",
    "    - 1번 코드는 기본적인 개선 방법을 제시하지만, 2번 코드는 다양한 데이터셋과 상황에 적용 가능한 보다 범용적인 모델 개선 방법을 탐색합니다. \n",
    "    - 이를 통해 다양한 도메인의 질문에 대해 적절한 응답을 생성할 수 있는 모델을 개발할 수 있습니다.\n",
    "- 성능 지표\n",
    "    - 2번 코드는 정량적 성능 지표(BLEU 점수, 정확도 등)에 있어서도 1번 코드보다 우수한 성과를 보입니다. \n",
    "    - 이는 데이터 전처리의 품질 향상, 학습 전략의 최적화, 그리고 모델 구조의 세심한 조정을 통해 가능해진 결과입니다.\n",
    "\n",
    "### 결론\n",
    "1번 코드와 2번 코드를 비교할 때, 2번 코드는 데이터 전처리 및 모델 학습 과정에서의 고급 전략 적용을 통해 KoChatGPT 모델의 성능을 획기적으로 향상시키는 방법을 제시합니다. 이러한 접근법은 모델이 더 정확하고 자연스러운 응답을 생성하도록 돕고, 다양한 도메인과 상황에 대응할 수 있는 강력한 대화형 AI 모델 개발을 가능하게 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52122978",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "데이터 전처리의 중요성\n",
    "- 모델의 성능은 대량의 데이터와 그 데이터의 품질에 크게 의존한다.\n",
    "- 데이터 전처리 과정에서 불필요한 정보를 제거하고, 모델이 학습하기에 적합한 형태로 데이터를 정제하는 것이 중요하다.\n",
    "\n",
    "모델 선택과 적용\n",
    "- 다양한 모델(SFT, RM, PPO)을 적용해보며, 각 모델의 특성과 장단점을 이해할 수 있다. \n",
    "- 특히, 특정 상황에 가장 적합한 모델을 선택하는 것이 성능 향상에 결정적인 역할을 했다.\n",
    "\n",
    "이 프로젝트를 통해, 복잡한 자연어 처리 문제를 해결하기 위한 다양한 기술과 접근 방식에 대해 깊이 있게 이해할 수 있었다.   \n",
    "또한, 실제 문제에 이러한 기술들을 적용해보며, 이론과 실제의 차이를 경험하고, 실제 문제 해결 능력을 키울 수 있었다.  \n",
    "이러한 경험은 앞으로 AI 분야에서 더 복잡한 문제에 도전할 때 큰 도움이 될 것같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
